# **10일 완성\! 실무 역량을 위한 AI 프로그래밍 부트캠프: PyTorch와 Gemini API를 활용한 모델 개발부터 애플리케이션 구축까지**

## **과정 소개**

본 보고서는 인공지능(AI) 프로그래밍을 처음 접하는 공학도를 대상으로, 10일간의 집중 교육을 통해 간단한 AI 모델 및 API 기반 애플리케이션을 제작할 수 있는 역량을 갖추도록 설계된 종합 커리큘럼을 제시합니다. 본 과정은 단순한 도구 사용법 학습을 넘어, AI 모델의 작동 원리에 대한 깊이 있는 이해와 실제 문제 해결 능력을 겸비한 'AI 개발자' 양성을 궁극적인 목표로 삼습니다.

### **과정 철학 및 목표**

본 부트캠프의 교육 철학은 이론과 실습의 유기적인 결합에 있습니다. 전체 교육 과정은 이론(40%)과 실습(60%)의 균형을 엄격하게 유지하여, 수강생들이 기술의 '왜(Why)'와 '어떻게(How)'를 모두 체득하도록 설계되었습니다. 이를 통해 수강생들은 변화하는 기술 환경에 능동적으로 대처하고, 새로운 문제를 만났을 때 스스로 해결책을 모색할 수 있는 근본적인 힘을 기르게 됩니다.

최종 교육 목표는 다음과 같습니다:

1. PyTorch 프레임워크를 활용하여 합성곱 신경망(CNN), 순환 신경망(RNN) 등 핵심적인 딥러닝 모델을 직접 구현하고 학습시키는 능력 배양.  
2. Google의 최신 대규모 언어 모델(LLM)인 Gemini API를 활용하여 텍스트 생성, 이미지 분석 등 고도화된 AI 기능을 애플리케이션에 통합하는 능력 확보.  
3. 10일간 습득한 모든 기술을 종합하여, 팀 프로젝트를 통해 실제 작동하는 AI 기반 애플리케이션을 기획부터 개발, 발표까지 완료하는 실무 경험 습득.

### **기술 스택 및 학습 환경**

본 과정은 현재 산업계에서 가장 널리 사용되는 표준적인 기술 스택을 기반으로 구성되었습니다. 수강생들은 교육 수료 후 즉시 현업 프로젝트에 투입될 수 있는 기술적 준비 상태를 갖추게 됩니다.

* **주요 언어:** Python  
* **핵심 라이브러리:** NumPy, Pandas, Matplotlib, Seaborn, PyTorch  
* **개발 환경:** Google Colab. 모든 수강생은 별도의 로컬 환경 설정 없이 웹 브라우저만으로 실습에 참여할 수 있습니다. 특히, Google Colab이 제공하는 무료 GPU 지원은 복잡한 딥러닝 모델의 학습 시간을 획기적으로 단축시켜, 제한된 시간 내에 깊이 있는 실습을 가능하게 합니다. 이는 모든 수강생이 동일한 고성능 컴퓨팅 환경에서 학습에만 집중할 수 있도록 보장하는 핵심 요소입니다.  
* **API 및 애플리케이션:** Google Gemini API, Streamlit. Streamlit은 Python 코드만으로 빠르게 인터랙티브 웹 애플리케이션을 제작할 수 있게 해주는 프레임워크로, 개발한 AI 모델을 최종 사용자가 쉽게 사용할 수 있는 서비스로 만드는 경험을 제공합니다.

### **10일 AI 프로그래밍 부트캠프 전체 일정표**

다음 표는 10일간 진행될 부트캠프의 전체적인 흐름을 요약한 것입니다. 이 일정표는 강사와 수강생 모두에게 전체 교육 과정의 로드맵을 제시하며, 각 일차별 학습 목표와 활동을 명확히 인지하는 데 도움을 줄 것입니다.

| 일차 | 오전 세션 (09:00-12:00) | 오후 세션 (13:00-18:00) | 핵심 학습 목표 | 주요 실습 |
| :---- | :---- | :---- | :---- | :---- |
| **1일차** | **이론:** AI의 큰 그림과 머신러닝 워크플로우 | **실습:** 수치 연산의 핵심, NumPy | AI, ML, DL의 관계 이해 및 벡터화 연산의 중요성 체득 | NumPy ndarray 생성, 조작 및 벡터화 연산 실습 |
| **2일차** | **실습:** 데이터 조작의 연금술, Pandas | **실습:** 데이터 시각화, Matplotlib & Seaborn | 데이터 정제 및 탐색적 데이터 분석(EDA) 능력 배양 | 실제 데이터를 활용한 데이터 클리닝 및 시각화 |
| **3일차** | **이론/실습:** PyTorch의 심장, 텐서(Tensor) | **이론/실습:** 자동 미분의 마법, torch.autograd | GPU 기반 텐서 연산 및 딥러닝 학습 원리(역전파) 이해 | 선형 회귀 모델 수동 구현 및 그래디언트 계산 |
| **4일차** | **이론/실습:** 모델의 뼈대, nn.Module | **이론/실습:** 학습의 엔진, 옵티마이저와 데이터로더 | PyTorch를 이용한 신경망 구축 및 학습 파이프라인 완성 | nn.Module과 DataLoader를 활용한 학습 루프 구현 |
| **5일차** | **이론:** 이미지를 보는 눈, CNN | **실습:** CIFAR-10 이미지 분류기 제작 | CNN의 구조(합성곱, 풀링)와 작동 원리 이해 | torchvision과 nn.Conv2d를 사용한 CNN 모델링 |
| **6일차** | **이론:** 시간의 흐름을 읽다, RNN/LSTM | **실습:** 문자 단위 RNN으로 국적 분류하기 | 순차 데이터 처리와 RNN/LSTM의 장기 의존성 문제 해결 방식 이해 | 가변 길이 텍스트 데이터를 처리하는 RNN 모델링 |
| **7일차** | **이론:** 거인의 어깨 위에서, 트랜스포머 & 어텐션 | **실습:** Gemini API 첫걸음 | 트랜스포머와 셀프 어텐션 메커니즘의 개념적 이해 | Gemini API를 활용한 텍스트 생성 및 멀티모달 입력 처리 |
| **8일차** | **실습:** Python으로 웹 UI 만들기, Streamlit | **실습:** Gemini API 연동 대화형 챗봇 제작 | AI 모델을 서비스로 배포하기 위한 웹 애플리케이션 개발 능력 습득 | st.session\_state를 활용한 대화형 챗봇 구현 |
| **9일차** | **프로젝트:** 최종 프로젝트 기획 및 개발 스프린트 1 | **프로젝트:** 개발 스프린트 1 (계속) | 팀 협업을 통한 실전 AI 애플리케이션 기획 및 핵심 기능 개발 | 팀별 프로젝트 아키텍처 설계 및 역할 분담, 개발 착수 |
| **10일차** | **프로젝트:** 개발 스프린트 2 및 발표 준비 | **프로젝트:** 최종 발표 및 과정 수료 | 프로젝트 완성, 발표 및 동료/강사 피드백을 통한 종합 역량 강화 | 팀별 프로젝트 결과물 발표 및 시연, 과정 회고 |

---

## **일자별 상세 강의 계획**

### **1일차: AI의 초석 \- 데이터 과학을 위한 Python 마스터하기**

#### **오전 (09:00-12:00) \- 이론: 인공지능의 큰 그림과 머신러닝 워크플로우**

첫날 오전 세션은 기술적 깊이보다 '관점'을 제공하는 데 중점을 둡니다. 수강생들이 앞으로 10일간 배울 구체적인 기술들이 전체 AI 개발 프로세스에서 어떤 위치를 차지하는지 큰 지도를 그려줌으로써, 학습 동기를 부여하고 지식의 파편화를 방지합니다.

* **인공지능, 머신러닝, 딥러닝:** 인공지능(AI)을 가장 넓은 개념으로, 머신러닝(ML)을 데이터를 통해 학습하는 AI의 한 분야로, 그리고 딥러닝(DL)을 인공 신경망을 사용하는 머신러닝의 한 분야로 정의하며 이들의 포함 관계를 명확히 합니다.  
* **학습 방식의 분류:** 데이터에 정답(레이블)이 있는지 여부에 따라 지도학습(Supervised Learning), 정답 없이 데이터 자체의 구조를 학습하는 비지도학습(Unsupervised Learning), 그리고 보상을 통해 행동을 학습하는 강화학습(Reinforcement Learning)으로 구분하고, 각각의 대표적인 예시(이미지 분류, 군집 분석, 게임 AI 등)를 소개합니다.  
* **머신러닝 프로젝트 생명주기:** 하나의 머신러닝 프로젝트가 어떤 단계를 거쳐 완성되는지 전체적인 흐름을 제시합니다. (1) 문제 정의 → (2) 데이터 수집 및 전처리 → (3) 모델링 → (4) 학습 → (5) 평가 → (6) 배포 및 모니터링의 6단계 워크플로우를 설명하며, 이번 부트캠프가 이 모든 단계를 경험하는 과정임을 강조합니다.

#### **오후 (13:00-18:00) \- 실습: 수치 연산의 핵심, NumPy**

딥러닝은 본질적으로 거대한 행렬과 벡터의 연산입니다. 오후 실습은 Python에서 이러한 대규모 수치 데이터를 빠르고 효율적으로 다루는 기본 도구인 NumPy를 마스터하는 데 집중합니다.

* **NumPy의 필요성:** Python의 기본 리스트(list)와 반복문(for-loop)은 대규모 데이터 연산에 매우 비효율적입니다. NumPy의 핵심 데이터 구조인 ndarray는 내부적으로 C언어로 구현되어 있으며, '벡터화(vectorized) 연산'을 통해 반복문 없이 전체 배열에 대한 연산을 한 번에 수행함으로써 압도적인 성능을 제공합니다. 이 개념은 딥러닝 프레임워크인 PyTorch의 텐서 연산에서도 동일하게 적용되므로, NumPy 단계에서 벡터화 사고방식을 체득하는 것은 매우 중요합니다.  
* **핵심 기능 실습:**  
  * **ndarray 생성 및 조작:** np.array(), np.zeros(), np.ones(), np.arange() 등 다양한 방법으로 배열을 생성하고, shape, ndim, dtype 속성을 확인합니다. reshape() 함수를 이용해 배열의 형태를 자유자재로 변경하는 실습을 진행합니다.  
  * **인덱싱과 슬라이싱:** 특정 원소나 부분 배열에 접근하는 방법을 익힙니다.  
  * **벡터화 연산과 브로드캐스팅:** 배열 간의 사칙연산, np.sum(), np.mean(), np.dot() (행렬 곱) 등 주요 연산을 실습합니다. 특히, 크기가 다른 배열 간의 연산을 가능하게 하는 브로드캐스팅(broadcasting) 규칙을 이해하고 예제를 통해 익힙니다.  
  * **불리언 마스킹:** array \> 5와 같은 조건식을 사용해 True/False로 이루어진 마스크 배열을 만들고, 이를 인덱스로 사용하여 특정 조건을 만족하는 데이터만 효율적으로 추출하는 방법을 실습합니다.

실습 자료는 dataquest.io와 같은 검증된 교육 플랫폼의 튜토리얼과 연습 문제를 기반으로 구성하여, 수강생들이 체계적으로 개념을 익히고 실력을 검증할 수 있도록 합니다. 이 날 NumPy의 벡터화 연산에 대한 철저한 이해를 다지는 것은, 3일차에 배울 PyTorch 텐서 학습의 효율성을 극대화하는 직접적인 밑거름이 됩니다.

### **2일차: 데이터 길들이기 \- Pandas와 Matplotlib**

#### **오전 (09:00-12:00) \- 실습: 데이터 조작의 연금술, Pandas**

AI 모델의 성능은 데이터의 품질에 크게 좌우됩니다. Pandas는 정형 데이터를 불러오고, 정제하며, 원하는 형태로 가공하는 데 필수적인 라이브러리입니다.

* **핵심 자료구조:** Pandas의 두 가지 핵심 자료구조인 1차원 배열 Series와 2차원 테이블 DataFrame의 생성 방법과 기본 조작법을 익힙니다.  
* **데이터 입출력:** pd.read\_csv(), pd.read\_excel() 함수를 사용하여 로컬 파일 시스템에 있는 데이터를 DataFrame으로 불러오고, 처리된 결과를 다시 파일로 저장하는 방법을 실습합니다.  
* **데이터 정제(Data Cleaning):**  
  * **결측치 처리:** isnull(), dropna(), fillna() 함수를 이용해 데이터에 포함된 빈 값(결측치)을 확인하고 제거하거나 다른 값으로 대체하는 방법을 배웁니다.  
  * **데이터 타입 변환:** 문자열로 저장된 날짜 데이터를 pd.to\_datetime을 이용해 날짜/시간 타입으로 변환하는 등, 분석에 적합한 형태로 데이터 타입을 바꾸는 실습을 진행합니다.  
* **데이터 선택 및 가공:**  
  * **선택:** loc (레이블 기반)과 iloc (정수 위치 기반) 인덱서를 사용해 원하는 행과 열을 정밀하게 선택하는 방법을 마스터합니다.  
  * **필터링:** 불리언 마스킹과 유사하게, df\[df\['column'\] \> value\]와 같은 조건식을 통해 원하는 데이터를 필터링합니다.  
  * **그룹화 및 집계:** groupby() 메소드를 사용해 특정 열의 값을 기준으로 데이터를 그룹화하고, sum(), mean(), count() 등 집계 함수나 여러 집계를 한 번에 적용하는 agg() 함수를 활용하는 방법을 실습합니다.

실습에는 Kaggle의 '중고차 가격 데이터셋'이나 '비디오 게임 판매량 데이터셋'과 같은 실제 데이터를 사용하여, 수강생들이 현실적인 데이터 정제 및 탐색 과제를 해결하는 경험을 쌓도록 합니다.

#### **오후 (13:00-18:00) \- 실습: 데이터에 생명 불어넣기, Matplotlib & Seaborn 시각화**

데이터 시각화는 단순히 결과를 예쁘게 보여주는 기술이 아니라, 데이터에 숨겨진 패턴과 문제점을 발견하고 모델의 성능을 진단하는 핵심적인 분석 능력입니다.

* **Matplotlib 기초:** Python의 표준 시각화 라이브러리인 Matplotlib을 사용하여 기본적인 그래프를 그리는 방법을 배웁니다. plt.plot() (선 그래프), plt.bar() (막대 그래프), plt.scatter() (산점도), plt.hist() (히스토그램) 등의 함수를 익히고, plt.title(), plt.xlabel(), plt.ylabel() 등으로 그래프의 각 요소를 커스터마이징하는 방법을 실습합니다.  
* **Seaborn 활용:** Matplotlib 기반으로 만들어져 더 적은 코드로 미려하고 통계적인 정보를 담은 그래프를 그릴 수 있는 Seaborn 라이브러리를 소개합니다.  
* **탐색적 데이터 분석 (EDA):** 오전 Pandas 실습에서 정제한 데이터를 바탕으로 본격적인 EDA를 수행합니다. 변수들의 분포를 히스토그램이나 박스 플롯으로 확인하고, 변수 간의 관계를 산점도나 상관관계 히트맵으로 시각화하여 데이터로부터 의미 있는 인사이트를 도출하는 과정을 직접 경험합니다.

이 날의 시각화 훈련은 5, 6일차 모델링 과정에서 발생할 수 있는 문제들, 예를 들어 모델이 특정 데이터에 대해서만 유독 낮은 성능을 보이는 경우, 해당 데이터의 분포를 시각적으로 분석하여 원인을 진단하는 '디버깅 도구'를 미리 제공하는 것과 같습니다. 이는 단순 리포팅을 넘어선 실용적인 문제 해결 능력의 기반이 됩니다.

### **3일차: 딥러닝의 문을 열다 \- PyTorch 기초**

#### **오전 (09:00-12:00) \- 이론 및 실습: PyTorch의 심장, 텐서(Tensor)**

PyTorch는 NumPy와 매우 유사한 구조를 가지지만, GPU를 활용한 가속 연산이 가능하다는 결정적인 차이점을 가집니다. 이 세션에서는 NumPy의 지식을 바탕으로 PyTorch의 핵심인 텐서의 개념과 사용법을 익힙니다.

* **텐서란 무엇인가:** 텐서는 다차원 배열을 나타내는 PyTorch의 기본 데이터 구조입니다. NumPy의 ndarray와 개념적으로 동일하지만, GPU 연산을 지원하여 딥러닝의 대규모 병렬 계산을 효율적으로 처리할 수 있습니다.  
* **텐서 생성 및 조작:** torch.tensor(), torch.randn(), torch.zeros() 등 다양한 함수를 이용해 텐서를 생성하고, NumPy에서와 같이 인덱싱, 슬라이싱, view()(NumPy의 reshape과 유사)를 통해 텐서를 조작하는 방법을 실습합니다.  
* **GPU 활용:** Google Colab의 런타임 유형을 GPU로 변경하는 방법을 배우고, .to('cuda') 메소드를 사용하여 생성한 텐서를 CPU 메모리에서 GPU 메모리로 이동시켜 연산 속도를 비약적으로 향상시키는 과정을 직접 체험합니다.  
* **자료 활용:** 파이토치 한국어 튜토리얼과 커뮤니티 자료를 적극적으로 활용하여 수강생들이 친숙한 언어로 개념을 정확히 이해하도록 돕습니다.

#### **오후 (13:00-18:00) \- 이론 및 실습: 자동 미분의 마법, torch.autograd**

autograd는 PyTorch가 딥러닝 프레임워크로서 가지는 가장 강력한 기능 중 하나입니다. 이 세션은 '모델이 학습한다'는 추상적인 개념을 '손실 함수의 그래디언트를 계산하여 파라미터를 업데이트하는 구체적인 과정'으로 바꾸는 결정적인 경험을 제공합니다.

* **딥러닝 학습의 원리:**  
  * **경사하강법(Gradient Descent):** 모델의 예측값과 실제 정답 간의 차이, 즉 '손실(loss)'을 최소화하는 파라미터 값을 찾는 과정을 '산에서 가장 낮은 지점을 찾아 내려가는 것'에 비유하여 설명합니다. 이때 어느 방향으로 가야 가장 가파른 내리막길인지를 알려주는 것이 '기울기(gradient)'입니다.  
  * **역전파(Backpropagation):** 복잡한 신경망에서 각 파라미터가 최종 손실에 얼마나 영향을 미쳤는지(기울기)를 출력층에서부터 입력층 방향으로 연쇄 법칙(chain rule)을 이용해 효율적으로 계산하는 알고리즘입니다. 복잡한 수학 공식 대신 '오차에 대한 각 부품의 책임량을 계산하는 과정'이라는 직관적인 설명에 집중합니다.1  
* **autograd 실습:**  
  * **계산 그래프:** PyTorch가 수행하는 모든 텐서 연산은 계산 그래프라는 자료구조로 기록됩니다.  
  * **requires\_grad=True:** 텐서를 생성할 때 이 속성을 True로 설정하면, 해당 텐서에 대한 모든 연산이 그래프에 추적되어 기울기를 계산할 수 있게 됩니다.  
  * **loss.backward():** 손실 텐서에 대해 .backward() 메소드를 호출하면, 계산 그래프를 따라 역전파가 자동으로 수행되고, requires\_grad=True로 설정된 모든 텐서의 .grad 속성에 기울기 값이 계산되어 저장됩니다.  
* **실습 과제:** 간단한 선형 회귀 모델(y=w×x+b)을 PyTorch 텐서 연산만으로 구현합니다. 손실 함수(loss=∑((w×x+b)−y)2)를 직접 정의하고, loss.backward()를 호출하여 w.grad와 b.grad에 기울기가 계산되는 것을 확인합니다. 마지막으로, w \= w \- learning\_rate \* w.grad와 같이 경사하강법 공식을 직접 코드로 작성하여 파라미터를 업데이트하고, 반복을 통해 손실이 점차 줄어드는 과정을 눈으로 확인합니다. 이 '수동' 학습 경험은 4일차에 배울 optimizer.step()이 내부적으로 이 과정을 자동화해준다는 사실을 깊이 있게 이해하는 기반이 됩니다.

### **4일차: 진짜 신경망 만들기 \- 모델 구축과 학습**

#### **오전 (09:00-12:00) \- 이론 및 실습: 모델의 뼈대, nn.Module과 손실 함수**

3일차에 수동으로 구현했던 신경망을 PyTorch가 제공하는 고수준 API를 통해 세련되고 재사용 가능한 형태로 만드는 방법을 배웁니다.

* **torch.nn.Module:** PyTorch에서 모든 신경망 모델은 nn.Module 클래스를 상속받아 정의됩니다.  
  * \_\_init\_\_(self) 메소드: 모델에 필요한 계층(layer)들을 정의하는 곳입니다. 예를 들어, self.layer1 \= nn.Linear(in\_features, out\_features)와 같이 선형 계층을 초기화합니다.  
  * forward(self, x) 메소드: 입력 데이터 x가 \_\_init\_\_에서 정의된 계층들을 어떤 순서로 통과하여 최종 출력값을 만드는지를 정의하는 곳입니다. 이 메소드는 모델 객체를 함수처럼 호출할 때(model(input\_data)) 내부적으로 실행됩니다.  
* **기본 레이어:** nn.Linear (완전 연결 계층), nn.ReLU (활성화 함수) 등 가장 기본적인 신경망 구성 요소의 사용법을 익힙니다.  
* **손실 함수:** torch.nn 패키지에는 자주 사용되는 손실 함수들이 미리 구현되어 있습니다. 회귀 문제에 주로 사용되는 nn.MSELoss (평균 제곱 오차)와, 분류 문제의 표준인 nn.CrossEntropyLoss의 개념과 사용법을 배웁니다.  
* **실습 과제:** 3일차에 구현했던 선형 회귀 모델을 nn.Module과 nn.Linear를 사용하여 클래스 형태로 재작성합니다.

#### **오후 (13:00-18:00) \- 이론 및 실습: 학습의 엔진, 옵티마이저와 데이터로더**

이 세션은 3일차에 수동으로 진행했던 파라미터 업데이트와 데이터 공급 과정을 PyTorch의 자동화된 도구로 대체하는 방법을 다룹니다. 이 추상화 과정을 통해 수강생들은 프레임워크의 가치를 깨닫고, 더 복잡한 모델링에 집중할 수 있는 기반을 마련합니다.

* **옵티마이저(Optimizer):** torch.optim 패키지는 경사하강법을 기반으로 한 다양한 파라미터 업데이트 알고리즘을 제공합니다. optim.SGD (확률적 경사하강법), optim.Adam 등 대표적인 옵티마이저의 개념적 차이를 배우고, 모델의 파라미터와 학습률(learning rate)을 전달하여 옵티마이저 객체를 생성하는 방법을 익힙니다.  
* **학습 루프(Training Loop):** PyTorch의 표준적인 학습 루프는 다음 3단계로 구성됩니다. 이 흐름은 모든 딥러닝 모델 학습의 기본이므로 반드시 숙지해야 합니다.  
  1. optimizer.zero\_grad(): 이전 반복에서 계산된 기울기 값을 초기화합니다.  
  2. loss.backward(): 현재 배치의 손실에 대한 기울기를 계산합니다.  
  3. optimizer.step(): 계산된 기울기를 바탕으로 모델의 파라미터를 업데이트합니다.  
* **Dataset과 DataLoader:** 대용량 데이터를 한 번에 메모리에 올리는 것은 비효율적입니다. PyTorch는 데이터를 효율적으로 관리하고 공급하기 위한 두 가지 클래스를 제공합니다.  
  * Dataset: 데이터와 해당 레이블을 하나씩 가져오는 로직을 정의하는 추상 클래스입니다.  
  * DataLoader: Dataset을 감싸, 지정된 배치(batch) 크기만큼 데이터를 묶고, 데이터를 섞거나(shuffle), 여러 개의 CPU 코어를 사용해 병렬로 데이터를 로드하는 등 편리한 기능을 제공합니다.  
* **실습 과제:** 간단한 가상 데이터셋을 Dataset 클래스로 정의하고, 이를 DataLoader로 감싸 배치 단위로 데이터를 공급받습니다. 이 데이터로더와 오전 세션에서 만든 모델, 그리고 옵티마이저를 결합하여 완전한 형태의 학습 루프를 처음부터 끝까지 코딩하고 실행합니다.

### **5일차: 이미지를 보는 눈 \- CNN (합성곱 신경망)**

#### **오전 (09:00-12:00) \- 이론: CNN의 시각적 직관**

이 세션에서는 이미지 데이터 처리에 특화된 CNN의 구조와 작동 원리를 시각적이고 직관적인 방식으로 이해합니다.

* **CNN의 등장 배경:** 기존의 완전 연결 신경망(FCN)을 이미지에 적용할 때 발생하는 문제점(공간 정보 소실, 파라미터 수의 폭발적 증가)을 설명하며 CNN의 필요성을 제시합니다.  
* **합성곱(Convolution) 연산:** CNN의 핵심 연산입니다. '커널(Kernel)' 또는 '필터(Filter)'라고 불리는 작은 행렬이 이미지 위를 이동(sliding)하면서, 이미지의 특정 부분과 커널의 원소별 곱셈 합을 계산합니다. 이 과정을 통해 이미지의 국소적인 특징(수직선, 수평선, 특정 색상, 질감 등)을 추출하는 '특징 맵(Feature Map)'이 생성됩니다. 이 과정을 시각 자료를 통해 명확히 보여줍니다.2  
* **주요 파라미터:** 채널(Channel, 예: RGB 3채널), 패딩(Padding, 이미지 경계의 정보 손실을 막기 위해 주변을 특정 값으로 채우는 것), 스트라이드(Stride, 커널의 이동 보폭)의 개념을 시각적으로 설명합니다.  
* **풀링(Pooling) 레이어:** 합성곱을 거친 특징 맵의 크기를 줄이는(downsampling) 역할을 합니다. 주로 사용되는 맥스 풀링(Max Pooling)은 특정 영역에서 가장 큰 값만 남기는 방식으로, 계산량을 줄이고 모델이 특징의 미세한 위치 변화에 덜 민감하게(translation invariance) 만들어줍니다.2  
* **특징 계층(Feature Hierarchy):** CNN은 여러 개의 합성곱과 풀링 레이어를 쌓아 구성됩니다. 초기 레이어에서는 선, 모서리 같은 단순하고 저수준의 특징을 학습하고, 뒤쪽 레이어로 갈수록 이들을 조합하여 눈, 코, 입과 같은 더 복잡하고 고수준의 특징을 학습하게 됩니다. 이 특징의 계층적 구조가 CNN이 이미지를 효과적으로 인식하는 원리임을 설명합니다.

#### **오후 (13:00-18:00) \- 실습: CIFAR-10 이미지 분류기 제작**

오전의 이론을 바탕으로, 4일간 배운 모든 PyTorch 지식을 총동원하여 실제 이미지 분류기를 제작합니다. 이 실습은 딥러닝 이론이 어떻게 구체적인 코드로 변환되는지 명확히 이해하는 통합적인 경험을 제공합니다.

* **데이터 준비:** torchvision 라이브러리를 사용하여 CIFAR-10 데이터셋을 쉽게 다운로드하고, 이미지 픽셀 값을 특정 범위로 조정하는 정규화(normalization) 등 필요한 전처리를 적용합니다. DataLoader를 이용해 학습 및 테스트 데이터를 준비합니다.3  
* **CNN 모델 정의:** nn.Module을 상속받아 CNN 모델 클래스를 정의합니다. \_\_init\_\_ 메소드 안에서 nn.Conv2d (2D 합성곱 레이어)와 nn.MaxPool2d (2D 맥스 풀링 레이어)를 사용하여 모델의 구조를 설계합니다. 예를 들어, self.conv1 \= nn.Conv2d(3, 6, 5\) 코드는 '입력 채널 3개(RGB)를 받아, 5x5 크기의 커널 6개를 사용해 6개의 특징 맵을 출력한다'는 의미임을 오전 이론과 연결하여 설명합니다.3  
* **학습 및 평가:** 분류 문제이므로 손실 함수로 nn.CrossEntropyLoss를, 옵티마이저로 optim.SGD를 설정합니다.3 4일차에 배운 학습 루프 구조에 따라 모델을 학습시키고, 테스트 데이터셋으로 정확도를 측정하여 모델의 성능을 평가합니다.

실습은 PyTorch 공식 CIFAR-10 튜토리얼을 기반으로, 각 코드 라인의 의미를 되짚으며 단계별로 진행하여 수강생들이 스스로 모델을 완성할 수 있도록 유도합니다.3

### **6일차: 시간의 흐름을 읽다 \- RNN (순환 신경망)**

#### **오전 (09:00-12:00) \- 이론: 순차 데이터와 RNN/LSTM의 원리**

CNN이 공간적 구조를 가진 데이터를 다루는 데 특화되었다면, RNN은 시간적 순서나 연속성을 가진 데이터(순차 데이터)를 처리하기 위해 고안되었습니다.

* **순차 데이터의 특징:** 텍스트, 음성, 주가 데이터 등 순서가 중요한 데이터의 예시를 들고, 각 요소가 독립적이라고 가정하는 기존 모델들의 한계를 설명합니다.  
* **RNN (Recurrent Neural Network)의 핵심 아이디어:** RNN은 네트워크 내부에 '순환(loop)' 구조를 가지고 있습니다. 각 타임스텝에서 입력을 처리할 때, 이전 타임스텝의 처리 결과인 '은닉 상태(Hidden State)'를 함께 입력으로 사용합니다. 이를 통해 과거의 정보를 기억하고 현재를 이해하는 데 활용합니다.  
* **장기 의존성 문제:** RNN은 이론적으로는 과거 정보를 모두 기억할 수 있지만, 실제로는 시퀀스가 길어질수록 초반의 정보가 뒤로 전달되면서 희석되거나 왜곡되는 '장기 의존성 문제(Long-Term Dependency Problem)'를 겪습니다. 이는 역전파 과정에서 기울기가 점차 사라지거나(Vanishing Gradient) 폭발적으로 커지는(Exploding Gradient) 현상 때문에 발생합니다.  
* **LSTM (Long Short-Term Memory)의 해결책:** LSTM은 이 문제를 해결하기 위해 고안된 진보된 RNN 구조입니다.  
  * **셀 상태(Cell State):** LSTM의 핵심으로, '메모리 컨베이어 벨트'에 비유됩니다. 정보가 큰 변화 없이 시퀀스를 따라 길게 전달될 수 있는 통로 역할을 합니다.4  
  * **게이트(Gates):** 셀 상태에 정보를 추가하거나 제거하는 것을 정교하게 제어하는 3개의 게이트로 구성됩니다.4  
    1. **Forget Gate:** 과거 정보 중 무엇을 잊을지 결정합니다.  
    2. **Input Gate:** 현재 정보 중 무엇을 새로 기억할지 결정합니다.  
    3. Output Gate: 현재 셀 상태를 바탕으로 무엇을 출력(다음 은닉 상태)으로 내보낼지 결정합니다.  
       Christopher Olah의 블로그 "Understanding LSTMs"의 명료한 시각 자료를 활용하여 각 게이트의 역할을 직관적으로 설명합니다.4

#### **오후 (13:00-18:00) \- 실습: 문자 단위(Character-level) RNN으로 이름 국적 분류하기**

이 실습은 고정된 크기의 입력을 다루던 CNN과 달리, 길이가 다른 순차 데이터를 다루는 새로운 패러다임을 제시합니다. 이를 통해 수강생들은 '데이터의 구조에 따라 적합한 모델 아키텍처가 달라진다'는 딥러닝의 핵심 원칙을 체득하게 됩니다.

* **데이터 전처리:** 텍스트 데이터를 모델이 이해할 수 있는 숫자 형태로 변환합니다. 각 문자를 고유한 정수 인덱스로 매핑하고, 이 인덱스를 다시 '원-핫 벡터(one-hot vector)' 형태의 텐서로 변환하는 과정을 실습합니다. 예를 들어, "Smith"(5글자)와 "Schmidhuber"(11글자)처럼 길이가 다른 이름들을 처리하는 방법을 배웁니다.5  
* **RNN 모델 정의:** nn.Module을 상속받아 nn.RNN 또는 nn.LSTM 레이어를 사용하여 문자 단위 RNN 모델 클래스를 정의합니다. 모델은 한 번에 한 문자씩 순차적으로 입력을 받아 내부의 은닉 상태를 업데이트합니다.5  
* **학습 및 예측:** 모델을 학습시킨 후, 새로운 이름(예: "Satoshi", "Jackson")을 입력하여 어느 나라 이름일지 예측하는 코드를 실행해 봅니다. 이 과정을 통해 RNN이 어떻게 순차적 패턴을 학습하는지 직접 확인합니다.5

실습은 PyTorch 공식 "NLP From Scratch" 튜토리얼을 기반으로 하여, 수강생들이 신뢰할 수 있는 자료를 바탕으로 단계별로 따라 하며 개념을 익힐 수 있도록 안내합니다.5

### **7일차: 거인의 어깨 위에서 \- LLM과 Gemini API**

#### **오전 (09:00-12:00) \- 이론: 트랜스포머와 어텐션 메커니즘**

이 세션은 현대 자연어 처리(NLP)의 근간이 되는 트랜스포머 아키텍처의 핵심 원리를 이해하는 데 초점을 맞춥니다.

* **RNN의 한계와 트랜스포머의 등장:** RNN/LSTM은 데이터를 순차적으로 처리해야 하므로 병렬화가 어렵고, 매우 긴 시퀀스에서는 여전히 정보 전달에 한계가 있습니다. 2017년 발표된 "Attention Is All You Need" 논문은 이러한 순환 구조를 완전히 제거하고 '어텐션(Attention)' 메커니즘만으로 더 뛰어난 성능을 달성한 트랜스포머 모델을 제안했습니다.  
* **셀프 어텐션(Self-Attention):** 트랜스포머의 핵심 아이디어입니다. 문장 내의 한 단어를 처리할 때, 문장 내의 다른 모든 단어들과의 연관성을 동시에 계산하여 어떤 단어에 더 '주목(attention)'해야 할지 결정합니다. 이 연관성은 각 단어로부터 파생된 3개의 벡터, 즉 **Query(질문)**, **Key(열쇠)**, \*\*Value(값)\*\*를 통해 계산됩니다. Query가 모든 Key와 비교되어 '유사도(어텐션 점수)'를 얻고, 이 점수를 가중치로 삼아 Value들의 가중합을 구하는 방식으로 작동합니다. 이를 통해 문맥을 효과적으로 파악할 수 있습니다.7  
* **트랜스포머 구조:** 인코더-디코더 구조를 가지며, 셀프 어텐션을 여러 개 병렬로 수행하는 '멀티헤드 어텐션(Multi-Head Attention)'을 통해 다양한 관점에서 문맥적 관계를 학습합니다.7  
* **자료 활용:** Jay Alammar의 블로그 "The Illustrated Transformer"는 복잡한 트랜스포머 구조를 매우 직관적인 그림으로 설명하여 전 세계적으로 큰 호응을 얻었습니다. 이 자료를 중심으로 시각적이고 개념적인 이해를 돕습니다.7

#### **오후 (13:00-18:00) \- 실습: Gemini API 첫걸음**

이 실습은 '모델을 직접 훈련하는' 패러다임에서 '미리 훈련된 거대 모델(Foundation Model)을 API로 활용하는' 패러다임으로의 전환을 의미합니다. 이는 AI 문제 해결에 대한 시각을 넓히고, 더 빠르고 효율적으로 솔루션을 구축하는 방법을 제시합니다.

* **API 키 발급 및 설정:** Google AI Studio에 접속하여 간단한 절차를 통해 Gemini API를 사용할 수 있는 무료 API 키를 발급받습니다.8  
* **Python SDK 설치 및 사용:** pip install \-U google-generativeai 명령어로 Python SDK를 설치하고, 발급받은 API 키를 코드에 설정합니다.8  
* **텍스트 생성:** model.generate\_content() 함수에 텍스트 프롬프트를 전달하여 Gemini 모델로부터 자연스러운 문장을 생성하는 가장 기본적인 기능을 실습합니다. 간단한 프롬프트 엔지니어링을 통해 응답의 스타일이나 내용을 제어하는 방법을 탐구합니다.8  
* **멀티모달(Multimodal) 입력 처리:** Gemini의 가장 큰 특징 중 하나는 텍스트와 이미지를 동시에 이해할 수 있다는 점입니다. 텍스트 프롬프트와 함께 이미지 파일을 입력으로 전달하여, 이미지에 대한 설명을 생성하거나 이미지 속 객체에 대해 질문하고 답변을 받는 실습을 진행합니다. 이 경험을 통해 수강생들은 이전에는 상상하기 어려웠던 고차원적인 AI 기능을 단 몇 줄의 코드로 구현할 수 있음을 체감하게 됩니다.9

### **8일차: AI를 서비스로 \- Streamlit 기반 애플리케이션 제작**

#### **오전 (09:00-12:00) \- 실습: Python으로 웹 UI 만들기, Streamlit**

지금까지의 결과물은 개발자 환경(Colab 노트북)에서만 의미가 있었습니다. 이 세션에서는 AI 모델의 결과물을 최종 사용자가 직접 상호작용할 수 있는 '서비스'로 변환하는 방법을 배웁니다.

* **Streamlit 철학:** 데이터 과학자와 머신러닝 엔지니어가 복잡한 웹 기술(HTML, CSS, JavaScript) 없이 Python 코드만으로 빠르고 쉽게 데이터 기반 웹 애플리케이션을 만들 수 있도록 돕는 것이 Streamlit의 핵심 철학입니다.  
* **기본 위젯:** st.title(), st.write(), st.button(), st.text\_input(), st.file\_uploader() 등 자주 사용되는 UI 컴포넌트(위젯)들의 사용법을 익힙니다.  
* **레이아웃:** st.sidebar()를 이용해 사이드바를 만들고, st.columns()로 화면을 여러 열로 분할하여 정보를 체계적으로 배치하는 방법을 배웁니다.  
* **상태 관리(State Management):** Streamlit 앱은 사용자의 상호작용이 있을 때마다 스크립트 전체를 다시 실행합니다. 이때 변수 값을 유지하기 위해 st.session\_state를 사용해야 합니다. st.session\_state는 앱의 세션 동안 유지되는 딕셔너리 객체로, 대화 기록이나 사용자의 선택 사항 등을 저장하는 데 필수적입니다.

#### **오후 (13:00-18:00) \- 실습: Gemini API와 Streamlit을 연동한 대화형 챗봇 만들기**

오전과 7일차에 배운 지식을 총동원하여, AI 엔지니어링의 꽃이라 할 수 있는 대화형 챗봇 애플리케이션을 처음부터 끝까지 제작합니다. 이 과정은 기술적 성과를 실제 가치로 연결하는 능력을 배양합니다.

* **챗봇 UI 구성:** st.chat\_message()를 사용해 사용자와 봇의 메시지를 구분하여 보여주는 말풍선 UI를 만들고, st.chat\_input()으로 사용자 입력을 받는 인터페이스를 구현합니다.  
* **대화 기록 관리:** st.session\_state에 'messages'라는 이름의 리스트를 만들어, 사용자와 챗봇의 대화를 순서대로 저장합니다. 앱이 재실행될 때마다 이 리스트를 순회하며 이전 대화 내용을 화면에 다시 그려줍니다.  
* **API 연동 로직:** 사용자가 st.chat\_input에 메시지를 입력하면, (1) 해당 메시지를 st.session\_state에 추가하고 화면에 표시한 뒤, (2) 저장된 전체 대화 기록을 Gemini API에 전달하여 문맥에 맞는 답변을 요청합니다. (3) API로부터 받은 응답을 다시 st.session\_state에 추가하고 화면에 표시하는 전체 로직을 구현합니다.  
* **코드 리뷰 및 구현:** GitHub에 공개된 다양한 Streamlit-Gemini 챗봇 예제 코드를 참고하여, 각 코드 라인의 역할을 이해하고 자신만의 챗봇을 완성하는 실습을 진행합니다.9 이 과정을 통해 수강생들은 단순히 모델을 만드는 것을 넘어, '사용자 경험(UX)'을 고려하며 실제 작동하는 서비스를 만드는 엔지니어의 관점을 갖게 됩니다.

### **9-10일차: 최종 관문 \- AI 애플리케이션 팀 프로젝트**

마지막 이틀은 개별 기술 학습을 넘어, '문제 정의, 기술 선택, 협업, 결과물 발표'라는 소프트웨어 엔지니어링의 축소판을 경험하는 종합적인 역량 평가의 장입니다.

#### **9일차 오전 (09:00-12:00) \- 프로젝트 기획**

* **목표 및 평가 기준:** 프로젝트의 목표는 '작동하는 AI 서비스 프로토타입 제작'이며, 평가는 기술적 완성도, 아이디어의 창의성, 문제 해결 접근 방식, 그리고 팀워크 및 발표 능력을 종합적으로 고려함을 공지합니다.  
* **아이디어 브레인스토밍:** 수강생들이 8일간 배운 내용을 바탕으로 자유롭게 아이디어를 제안하고 토론합니다. 강사는 다음과 같은 예시 아이디어를 제시하여 영감을 줍니다.  
  * **PyTorch 중심 프로젝트:** 특정 종류의 객체(예: 동물 10종, 재활용품 종류)를 분류하는 CNN 모델을 직접 훈련하고, Streamlit으로 이미지를 업로드하면 분류 결과를 보여주는 앱.  
  * **Gemini API 중심 프로젝트:** PDF나 이미지 형태의 강의 자료를 업로드하면 Gemini API가 내용을 요약하고, 사용자의 질문에 답변해주는 RAG(Retrieval-Augmented Generation) 기반의 학습 보조 챗봇.  
  * **멀티모달 활용 프로젝트:** 사용자가 업로드한 이미지에 대해 Gemini Vision API가 창의적인 이야기를 생성하고, Gemini TTS(Text-to-Speech) API가 그 이야기를 음성으로 읽어주는 '이미지 스토리텔러' 앱.  
* **팀 구성 및 아이디어 선정:** 수강생들은 관심사가 비슷한 동료들과 팀을 구성하고, 실현 가능성과 흥미를 고려하여 최종 프로젝트 아이디어를 선정합니다.

#### **9일차 오후 (13:00-18:00) \- 개발 스프린트 1**

* **설계 및 역할 분담:** 선정된 아이디어를 바탕으로 시스템 아키텍처(데이터 흐름, UI 구성 등)를 설계하고, 팀원 간 역할을 분담합니다(예: 데이터 전처리 담당, PyTorch 모델링 담당, Gemini API 연동 담당, Streamlit UI 담당).  
* **핵심 기능 개발:** 역할에 따라 핵심 기능 개발에 착수합니다. 강사와 조교는 각 팀을 순회하며 발생하는 기술적 문제를 해결해주고, 프로젝트 방향성에 대한 멘토링을 제공합니다.

#### **10일차 오전 (09:00-12:00) \- 개발 스프린트 2 및 발표 준비**

* **통합 및 디버깅:** 각자 개발한 기능들을 하나로 통합하고, 전체 시스템이 원활하게 작동하는지 테스트하며 최종 버그를 수정합니다.  
* **발표 준비:** 프로젝트의 목적, 사용 기술, 구현 과정, 그리고 시연 시나리오를 담은 발표 자료를 준비합니다. 가능하다면 Streamlit Community Cloud 등을 이용해 실제 웹에 배포를 시도합니다.

#### **10일차 오후 (13:00-18:00) \- 최종 발표 및 과정 수료**

* **최종 발표:** 각 팀은 정해진 시간(예: 발표 15분, Q\&A 5분) 동안 프로젝트 결과물을 발표하고 시연합니다. 단순히 '작동'하는 것을 넘어, 이 서비스가 어떤 문제를 어떻게 해결하는지 명확하게 전달하는 것이 중요합니다.  
* **피드백 및 회고:** 발표 후 동료들과 강사로부터 피드백을 주고받습니다. 마지막으로 과정 전체를 회고하며 배운 점과 아쉬운 점을 공유하는 시간을 갖습니다.  
* **수료:** 모든 과정을 성공적으로 마친 수강생들에게 수료증을 수여하며 부트캠프를 마무리합니다.

이 전 과정을 통해, 수강생들은 개별 기술 지식을 넘어 프로젝트를 완수하는 '실무 역량'을 체득하게 됩니다. 이는 본 부트캠프의 최종 목표인 '취업 가능한 주니어 AI 개발자 양성'에 가장 직접적으로 기여하는 핵심적인 활동입니다.

#### **참고 자료**

1. What is Backpropagation? | IBM, 7월 10, 2025에 액세스, [https://www.ibm.com/think/topics/backpropagation](https://www.ibm.com/think/topics/backpropagation)  
2. Convolutional Neural Networks, Explained | Towards Data Science, 7월 10, 2025에 액세스, [https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)  
3. Training a Classifier — PyTorch Tutorials 2.7.0+cu126 documentation, 7월 10, 2025에 액세스, [https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)  
4. Understanding LSTM Networks \-- colah's blog, 7월 10, 2025에 액세스, [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)  
5. NLP From Scratch: Classifying Names with a Character-Level RNN ..., 7월 10, 2025에 액세스, [https://pytorch.org/tutorials/intermediate/char\_rnn\_classification\_tutorial.html](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)  
6. NLP From Scratch: Classifying Names with a Character-Level RNN ..., 7월 10, 2025에 액세스, [https://docs.pytorch.org/tutorials/intermediate/char\_rnn\_classification\_tutorial.html](https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)  
7. The Illustrated Transformer \- Pelayo Arbués, 7월 10, 2025에 액세스, [https://www.pelayoarbues.com/literature-notes/Articles/The-Illustrated-Transformer](https://www.pelayoarbues.com/literature-notes/Articles/The-Illustrated-Transformer)  
8. Gemini API quickstart | Google AI for Developers, 7월 10, 2025에 액세스, [https://ai.google.dev/gemini-api/docs/quickstart?lang=python](https://ai.google.dev/gemini-api/docs/quickstart?lang=python)  
9. Image understanding | Gemini API | Google AI for Developers, 7월 10, 2025에 액세스, [https://ai.google.dev/gemini-api/docs/image-understanding](https://ai.google.dev/gemini-api/docs/image-understanding)  
10. Build a basic LLM chat app \- Streamlit Docs, 7월 10, 2025에 액세스, [https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps](https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps)